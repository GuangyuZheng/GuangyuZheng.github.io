<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《Deep contextualized word representations》阅读笔记]]></title>
    <url>%2F2019%2F01%2F02%2FDeep-contextualized-word-representations%2F</url>
    <content type="text"><![CDATA[研究内容这篇发表于NAACL 2018的文章提出了ELMo，ELMo是Embeddings from Language Models的缩写。顾名思义，ELMo是来自于语言模型的词语表征。作者认为好的词语表征应该能够解决以下两个问题： 能够对复杂的词语用法特点（例如语法和语义）进行建模 能够知道这些用法是如何随着语言环境发生变化的（例如一词多义） 作者将ELMo直接当作特征拼接到具体任务模型的词向量或者最高层的表示上，在QA，情感分析等6项NLP任务中，加入ELMo都能提升模型的表现。 方法概述双向语言模型对于一个包含$N$个tokens的序列$(t_1, t_2, …, t_N)$，前向语言模型计算的是给定$(t_1,…, t_{k-1})$, $t_k$出现的概率；反向语言模型与前向类似，只是序列的方向是相反的。具体可用以下公式表示： \begin{align} Forward LM: p(t_1, t_2, ..., t_N) &= \prod_{k=1}^{N} p(t_k | t_1, t_2, ..., t_{k-1}) \\ Backward LM: p(t_1, t_2, ..., t_N) &= \prod_{k=1}^{N} p(t_k | t_{k+1}, t_{k+2}, ..., t_{N}) \\ \end{align}ELMo使用双向LSTM作为双向语言模型，最大化目标函数： \sum_{k=1}^{N} (\log p(t_k | t_1, t_2, ..., t_{k-1}; \theta_x, \overrightarrow{\theta}_{LSTM}, \theta_s) \\ + \log p(t_k | t_{k+1}, t_{k+2}, ..., t_{N}; \theta_x, \overleftarrow{\theta}_{LSTM}, \theta_s))其中$\theta_x$是token层的参数，$\theta_s$是Softmax层的参数。 ELMoELMo使用了语言模型的所有中间层状态。给定一个$L$层的双向语言模型，对于每个token $t_K$，它的中间层状态的集合如下： \begin{align} R_k &= \{x_{k}^{LM}, \overrightarrow{h}_{k,j}^{LM}, \overleftarrow{h}_{k,j}^{LM} | j=1,...,L\} \\ &= \{h_{k,j}^{LM} | j=0,...,L\} \end{align}其中，$h_{k,0}^{LM}$是token层；对于每个双向LSTM层，$h_{k,j}^{LM} = [\overrightarrow{h}_{k,j}^{LM};\overleftarrow{h}_{k,j}^{LM}]$。 对于具体任务$task$，ELMo将集合$R_k$中的所有层进行线性组合，构建一维向量，具体公式如下： ELMo_{k}^{task} = E(R_k ; \theta^{task}) = \gamma^{task} \sum_{j=0}^{L} s_{j}^{task} h_{k,j}^{LM}其中，$s^{task}$是经过Softmax归一化后的权重，$\gamma^{task}$是标量，任务模型可以使用$\gamma^{task}$来对整个ELMo向量进行缩放，来辅助Optimization process。 对方法的思考 不同于传统的下文无关的词向量（每个词对应一个词向量），ELMo是上下文相关的（对于不同上下文的每个词的表示是不同的），因此有助于学习到丰富的词语表征； 深层网络有助于提取高级的特征，ELMo结合了语言模型中每层的状态来构建特征，这种做法有助于学习到丰富的词语表征。文章认为底层的LSTM捕获了语法信息，而高层的LSTM捕获了语义信息； ELMo考虑了网络正则化参数$\lambda$的大小，发现适合的$\lambda$是有益的； 在使用到具体任务之前，ELMo在任务的语料上进行了fine-tuning，这可以被视作进行了domain transfer。]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>语言模型</tag>
        <tag>表征学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F02%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
